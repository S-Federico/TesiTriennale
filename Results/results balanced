##############################################################
############  Results using threshold 0.9  ###################
##############################################################
C:\Users\fonde\PycharmProjects\Tesi triennale\venv\lib\site-packages\imblearn\utils\_validation.py:587: FutureWarning: Pass sampling_strategy=not majority as keyword args. From version 0.9 passing these as positional arguments will result in an error
  warnings.warn(
###################  Nearest Neighbors  ##################
Trained in : 0.03125
[[80 33]
 [47 66]]
              precision    recall  f1-score   support

           0       0.63      0.71      0.67       113
           1       0.67      0.58      0.62       113

    accuracy                           0.65       226
   macro avg       0.65      0.65      0.64       226
weighted avg       0.65      0.65      0.64       226

###################  Gradient Boosting Classifier  ##################
Trained in : 13.390625
[[ 87  26]
 [  7 106]]
              precision    recall  f1-score   support

           0       0.93      0.77      0.84       113
           1       0.80      0.94      0.87       113

    accuracy                           0.85       226
   macro avg       0.86      0.85      0.85       226
weighted avg       0.86      0.85      0.85       226

###################  Decision Tree  ##################
Trained in : 0.453125
[[63 50]
 [22 91]]
              precision    recall  f1-score   support

           0       0.74      0.56      0.64       113
           1       0.65      0.81      0.72       113

    accuracy                           0.68       226
   macro avg       0.69      0.68      0.68       226
weighted avg       0.69      0.68      0.68       226

###################  Random Forest  ##################
Trained in : 14.203125
[[ 75  38]
 [ 10 103]]
              precision    recall  f1-score   support

           0       0.88      0.66      0.76       113
           1       0.73      0.91      0.81       113

    accuracy                           0.79       226
   macro avg       0.81      0.79      0.78       226
weighted avg       0.81      0.79      0.78       226

###################  Naive Bayes  ##################
Trained in : 0.015625
[[93 20]
 [63 50]]
              precision    recall  f1-score   support

           0       0.60      0.82      0.69       113
           1       0.71      0.44      0.55       113

    accuracy                           0.63       226
   macro avg       0.66      0.63      0.62       226
weighted avg       0.66      0.63      0.62       226

###################  Ada Boost  ##################
Trained in : 3.234375
[[88 25]
 [15 98]]
              precision    recall  f1-score   support

           0       0.85      0.78      0.81       113
           1       0.80      0.87      0.83       113

    accuracy                           0.82       226
   macro avg       0.83      0.82      0.82       226
weighted avg       0.83      0.82      0.82       226

##############################################################
############  Results using threshold 0.7  ###################
##############################################################
C:\Users\fonde\PycharmProjects\Tesi triennale\venv\lib\site-packages\imblearn\utils\_validation.py:587: FutureWarning: Pass sampling_strategy=not majority as keyword args. From version 0.9 passing these as positional arguments will result in an error
  warnings.warn(
###################  Nearest Neighbors  ##################
Trained in : 0.03125
[[48 65]
 [45 68]]
              precision    recall  f1-score   support

           0       0.52      0.42      0.47       113
           1       0.51      0.60      0.55       113

    accuracy                           0.51       226
   macro avg       0.51      0.51      0.51       226
weighted avg       0.51      0.51      0.51       226

###################  Gradient Boosting Classifier  ##################
Trained in : 9.90625
[[85 28]
 [15 98]]
              precision    recall  f1-score   support

           0       0.85      0.75      0.80       113
           1       0.78      0.87      0.82       113

    accuracy                           0.81       226
   macro avg       0.81      0.81      0.81       226
weighted avg       0.81      0.81      0.81       226

###################  Decision Tree  ##################
Trained in : 0.34375
[[85 28]
 [26 87]]
              precision    recall  f1-score   support

           0       0.77      0.75      0.76       113
           1       0.76      0.77      0.76       113

    accuracy                           0.76       226
   macro avg       0.76      0.76      0.76       226
weighted avg       0.76      0.76      0.76       226

###################  Random Forest  ##################
Trained in : 11.421875
[[ 73  40]
 [ 10 103]]
              precision    recall  f1-score   support

           0       0.88      0.65      0.74       113
           1       0.72      0.91      0.80       113

    accuracy                           0.78       226
   macro avg       0.80      0.78      0.77       226
weighted avg       0.80      0.78      0.77       226

###################  Naive Bayes  ##################
Trained in : 0.015625
[[98 15]
 [71 42]]
              precision    recall  f1-score   support

           0       0.58      0.87      0.70       113
           1       0.74      0.37      0.49       113

    accuracy                           0.62       226
   macro avg       0.66      0.62      0.59       226
weighted avg       0.66      0.62      0.59       226

###################  Ada Boost  ##################
Trained in : 2.359375
[[89 24]
 [16 97]]
              precision    recall  f1-score   support

           0       0.85      0.79      0.82       113
           1       0.80      0.86      0.83       113

    accuracy                           0.82       226
   macro avg       0.82      0.82      0.82       226
weighted avg       0.82      0.82      0.82       226

##############################################################
############  Results using threshold 0.5  ###################
##############################################################
C:\Users\fonde\PycharmProjects\Tesi triennale\venv\lib\site-packages\imblearn\utils\_validation.py:587: FutureWarning: Pass sampling_strategy=not majority as keyword args. From version 0.9 passing these as positional arguments will result in an error
  warnings.warn(
###################  Nearest Neighbors  ##################
Trained in : 0.03125
[[53 60]
 [35 78]]
              precision    recall  f1-score   support

           0       0.60      0.47      0.53       113
           1       0.57      0.69      0.62       113

    accuracy                           0.58       226
   macro avg       0.58      0.58      0.57       226
weighted avg       0.58      0.58      0.57       226

###################  Gradient Boosting Classifier  ##################
Trained in : 8.046875
[[ 86  27]
 [ 13 100]]
              precision    recall  f1-score   support

           0       0.87      0.76      0.81       113
           1       0.79      0.88      0.83       113

    accuracy                           0.82       226
   macro avg       0.83      0.82      0.82       226
weighted avg       0.83      0.82      0.82       226

###################  Decision Tree  ##################
Trained in : 0.234375
[[70 43]
 [27 86]]
              precision    recall  f1-score   support

           0       0.72      0.62      0.67       113
           1       0.67      0.76      0.71       113

    accuracy                           0.69       226
   macro avg       0.69      0.69      0.69       226
weighted avg       0.69      0.69      0.69       226

###################  Random Forest  ##################
Trained in : 10.9375
[[ 84  29]
 [ 10 103]]
              precision    recall  f1-score   support

           0       0.89      0.74      0.81       113
           1       0.78      0.91      0.84       113

    accuracy                           0.83       226
   macro avg       0.84      0.83      0.83       226
weighted avg       0.84      0.83      0.83       226

###################  Naive Bayes  ##################
Trained in : 0.0
[[94 19]
 [67 46]]
              precision    recall  f1-score   support

           0       0.58      0.83      0.69       113
           1       0.71      0.41      0.52       113

    accuracy                           0.62       226
   macro avg       0.65      0.62      0.60       226
weighted avg       0.65      0.62      0.60       226

###################  Ada Boost  ##################
Trained in : 1.796875
[[86 27]
 [15 98]]
              precision    recall  f1-score   support

           0       0.85      0.76      0.80       113
           1       0.78      0.87      0.82       113

    accuracy                           0.81       226
   macro avg       0.82      0.81      0.81       226
weighted avg       0.82      0.81      0.81       226

##############################################################
############  Results using threshold 0.3  ###################
##############################################################
C:\Users\fonde\PycharmProjects\Tesi triennale\venv\lib\site-packages\imblearn\utils\_validation.py:587: FutureWarning: Pass sampling_strategy=not majority as keyword args. From version 0.9 passing these as positional arguments will result in an error
  warnings.warn(
###################  Nearest Neighbors  ##################
Trained in : 0.015625
[[52 61]
 [42 71]]
              precision    recall  f1-score   support

           0       0.55      0.46      0.50       113
           1       0.54      0.63      0.58       113

    accuracy                           0.54       226
   macro avg       0.55      0.54      0.54       226
weighted avg       0.55      0.54      0.54       226

###################  Gradient Boosting Classifier  ##################
Trained in : 6.171875
[[ 85  28]
 [ 12 101]]
              precision    recall  f1-score   support

           0       0.88      0.75      0.81       113
           1       0.78      0.89      0.83       113

    accuracy                           0.82       226
   macro avg       0.83      0.82      0.82       226
weighted avg       0.83      0.82      0.82       226

###################  Decision Tree  ##################
Trained in : 0.203125
[[80 33]
 [20 93]]
              precision    recall  f1-score   support

           0       0.80      0.71      0.75       113
           1       0.74      0.82      0.78       113

    accuracy                           0.77       226
   macro avg       0.77      0.77      0.76       226
weighted avg       0.77      0.77      0.76       226

###################  Random Forest  ##################
Trained in : 9.5
[[ 77  36]
 [ 10 103]]
              precision    recall  f1-score   support

           0       0.89      0.68      0.77       113
           1       0.74      0.91      0.82       113

    accuracy                           0.80       226
   macro avg       0.81      0.80      0.79       226
weighted avg       0.81      0.80      0.79       226

###################  Naive Bayes  ##################
Trained in : 0.015625
[[100  13]
 [ 82  31]]
              precision    recall  f1-score   support

           0       0.55      0.88      0.68       113
           1       0.70      0.27      0.39       113

    accuracy                           0.58       226
   macro avg       0.63      0.58      0.54       226
weighted avg       0.63      0.58      0.54       226

###################  Ada Boost  ##################
Trained in : 1.484375
[[82 31]
 [18 95]]
              precision    recall  f1-score   support

           0       0.82      0.73      0.77       113
           1       0.75      0.84      0.79       113

    accuracy                           0.78       226
   macro avg       0.79      0.78      0.78       226
weighted avg       0.79      0.78      0.78       226

##############################################################
############  Results using threshold 0.2  ###################
##############################################################
C:\Users\fonde\PycharmProjects\Tesi triennale\venv\lib\site-packages\imblearn\utils\_validation.py:587: FutureWarning: Pass sampling_strategy=not majority as keyword args. From version 0.9 passing these as positional arguments will result in an error
  warnings.warn(
###################  Nearest Neighbors  ##################
Trained in : 0.015625
[[71 42]
 [49 64]]
              precision    recall  f1-score   support

           0       0.59      0.63      0.61       113
           1       0.60      0.57      0.58       113

    accuracy                           0.60       226
   macro avg       0.60      0.60      0.60       226
weighted avg       0.60      0.60      0.60       226

###################  Gradient Boosting Classifier  ##################
Trained in : 5.453125
[[81 32]
 [18 95]]
              precision    recall  f1-score   support

           0       0.82      0.72      0.76       113
           1       0.75      0.84      0.79       113

    accuracy                           0.78       226
   macro avg       0.78      0.78      0.78       226
weighted avg       0.78      0.78      0.78       226

###################  Decision Tree  ##################
Trained in : 0.15625
[[61 52]
 [18 95]]
              precision    recall  f1-score   support

           0       0.77      0.54      0.64       113
           1       0.65      0.84      0.73       113

    accuracy                           0.69       226
   macro avg       0.71      0.69      0.68       226
weighted avg       0.71      0.69      0.68       226

###################  Random Forest  ##################
Trained in : 9.15625
[[ 75  38]
 [ 10 103]]
              precision    recall  f1-score   support

           0       0.88      0.66      0.76       113
           1       0.73      0.91      0.81       113

    accuracy                           0.79       226
   macro avg       0.81      0.79      0.78       226
weighted avg       0.81      0.79      0.78       226

###################  Naive Bayes  ##################
Trained in : 0.015625
[[95 18]
 [73 40]]
              precision    recall  f1-score   support

           0       0.57      0.84      0.68       113
           1       0.69      0.35      0.47       113

    accuracy                           0.60       226
   macro avg       0.63      0.60      0.57       226
weighted avg       0.63      0.60      0.57       226

###################  Ada Boost  ##################
Trained in : 1.34375
[[ 76  37]
 [ 13 100]]
              precision    recall  f1-score   support

           0       0.85      0.67      0.75       113
           1       0.73      0.88      0.80       113

    accuracy                           0.78       226
   macro avg       0.79      0.78      0.78       226
weighted avg       0.79      0.78      0.78       226

##############################################################
############  Results using threshold 0.1  ###################
##############################################################
C:\Users\fonde\PycharmProjects\Tesi triennale\venv\lib\site-packages\imblearn\utils\_validation.py:587: FutureWarning: Pass sampling_strategy=not majority as keyword args. From version 0.9 passing these as positional arguments will result in an error
  warnings.warn(
###################  Nearest Neighbors  ##################
Trained in : 0.015625
[[57 56]
 [43 70]]
              precision    recall  f1-score   support

           0       0.57      0.50      0.54       113
           1       0.56      0.62      0.59       113

    accuracy                           0.56       226
   macro avg       0.56      0.56      0.56       226
weighted avg       0.56      0.56      0.56       226

###################  Gradient Boosting Classifier  ##################
Trained in : 4.75
[[78 35]
 [14 99]]
              precision    recall  f1-score   support

           0       0.85      0.69      0.76       113
           1       0.74      0.88      0.80       113

    accuracy                           0.78       226
   macro avg       0.79      0.78      0.78       226
weighted avg       0.79      0.78      0.78       226

###################  Decision Tree  ##################
Trained in : 0.203125
[[66 47]
 [32 81]]
              precision    recall  f1-score   support

           0       0.67      0.58      0.63       113
           1       0.63      0.72      0.67       113

    accuracy                           0.65       226
   macro avg       0.65      0.65      0.65       226
weighted avg       0.65      0.65      0.65       226

###################  Random Forest  ##################
Trained in : 8.296875
[[ 78  35]
 [ 12 101]]
              precision    recall  f1-score   support

           0       0.87      0.69      0.77       113
           1       0.74      0.89      0.81       113

    accuracy                           0.79       226
   macro avg       0.80      0.79      0.79       226
weighted avg       0.80      0.79      0.79       226

###################  Naive Bayes  ##################
Trained in : 0.015625
[[109   4]
 [ 82  31]]
              precision    recall  f1-score   support

           0       0.57      0.96      0.72       113
           1       0.89      0.27      0.42       113

    accuracy                           0.62       226
   macro avg       0.73      0.62      0.57       226
weighted avg       0.73      0.62      0.57       226

###################  Ada Boost  ##################
Trained in : 1.171875
[[74 39]
 [20 93]]
              precision    recall  f1-score   support

           0       0.79      0.65      0.71       113
           1       0.70      0.82      0.76       113

    accuracy                           0.74       226
   macro avg       0.75      0.74      0.74       226
weighted avg       0.75      0.74      0.74       226

##############################################################
############  Results using threshold 0.05  ###################
##############################################################
C:\Users\fonde\PycharmProjects\Tesi triennale\venv\lib\site-packages\imblearn\utils\_validation.py:587: FutureWarning: Pass sampling_strategy=not majority as keyword args. From version 0.9 passing these as positional arguments will result in an error
  warnings.warn(
###################  Nearest Neighbors  ##################
Trained in : 0.015625
[[49 64]
 [40 73]]
              precision    recall  f1-score   support

           0       0.55      0.43      0.49       113
           1       0.53      0.65      0.58       113

    accuracy                           0.54       226
   macro avg       0.54      0.54      0.53       226
weighted avg       0.54      0.54      0.53       226

###################  Gradient Boosting Classifier  ##################
Trained in : 4.375
[[ 81  32]
 [ 12 101]]
              precision    recall  f1-score   support

           0       0.87      0.72      0.79       113
           1       0.76      0.89      0.82       113

    accuracy                           0.81       226
   macro avg       0.82      0.81      0.80       226
weighted avg       0.82      0.81      0.80       226

###################  Decision Tree  ##################
Trained in : 0.09375
[[45 68]
 [28 85]]
              precision    recall  f1-score   support

           0       0.62      0.40      0.48       113
           1       0.56      0.75      0.64       113

    accuracy                           0.58       226
   macro avg       0.59      0.58      0.56       226
weighted avg       0.59      0.58      0.56       226

###################  Random Forest  ##################
Trained in : 8.828125
[[ 78  35]
 [ 12 101]]
              precision    recall  f1-score   support

           0       0.87      0.69      0.77       113
           1       0.74      0.89      0.81       113

    accuracy                           0.79       226
   macro avg       0.80      0.79      0.79       226
weighted avg       0.80      0.79      0.79       226

###################  Naive Bayes  ##################
Trained in : 0.015625
[[102  11]
 [ 82  31]]
              precision    recall  f1-score   support

           0       0.55      0.90      0.69       113
           1       0.74      0.27      0.40       113

    accuracy                           0.59       226
   macro avg       0.65      0.59      0.54       226
weighted avg       0.65      0.59      0.54       226

###################  Ada Boost  ##################
Trained in : 1.109375
[[ 76  37]
 [ 13 100]]
              precision    recall  f1-score   support

           0       0.85      0.67      0.75       113
           1       0.73      0.88      0.80       113

    accuracy                           0.78       226
   macro avg       0.79      0.78      0.78       226
weighted avg       0.79      0.78      0.78       226

##############################################################
############  Results using threshold 0.01  ###################
##############################################################
C:\Users\fonde\PycharmProjects\Tesi triennale\venv\lib\site-packages\imblearn\utils\_validation.py:587: FutureWarning: Pass sampling_strategy=not majority as keyword args. From version 0.9 passing these as positional arguments will result in an error
  warnings.warn(
###################  Nearest Neighbors  ##################
Trained in : 0.0
[[82 31]
 [44 69]]
              precision    recall  f1-score   support

           0       0.65      0.73      0.69       113
           1       0.69      0.61      0.65       113

    accuracy                           0.67       226
   macro avg       0.67      0.67      0.67       226
weighted avg       0.67      0.67      0.67       226

###################  Gradient Boosting Classifier  ##################
Trained in : 2.765625
[[83 30]
 [18 95]]
              precision    recall  f1-score   support

           0       0.82      0.73      0.78       113
           1       0.76      0.84      0.80       113

    accuracy                           0.79       226
   macro avg       0.79      0.79      0.79       226
weighted avg       0.79      0.79      0.79       226

###################  Decision Tree  ##################
Trained in : 0.109375
[[66 47]
 [23 90]]
              precision    recall  f1-score   support

           0       0.74      0.58      0.65       113
           1       0.66      0.80      0.72       113

    accuracy                           0.69       226
   macro avg       0.70      0.69      0.69       226
weighted avg       0.70      0.69      0.69       226

###################  Random Forest  ##################
Trained in : 7.109375
[[77 36]
 [15 98]]
              precision    recall  f1-score   support

           0       0.84      0.68      0.75       113
           1       0.73      0.87      0.79       113

    accuracy                           0.77       226
   macro avg       0.78      0.77      0.77       226
weighted avg       0.78      0.77      0.77       226

###################  Naive Bayes  ##################
Trained in : 0.0
[[96 17]
 [50 63]]
              precision    recall  f1-score   support

           0       0.66      0.85      0.74       113
           1       0.79      0.56      0.65       113

    accuracy                           0.70       226
   macro avg       0.72      0.70      0.70       226
weighted avg       0.72      0.70      0.70       226

###################  Ada Boost  ##################
Trained in : 0.8125
[[84 29]
 [17 96]]
              precision    recall  f1-score   support

           0       0.83      0.74      0.79       113
           1       0.77      0.85      0.81       113

    accuracy                           0.80       226
   macro avg       0.80      0.80      0.80       226
weighted avg       0.80      0.80      0.80       226
