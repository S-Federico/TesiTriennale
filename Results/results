"C:\Users\fonde\PycharmProjects\Tesi triennale\venv\Scripts\python.exe" "C:/Users/fonde/PycharmProjects/Tesi triennale/Code/PD_Classification.py"
##############################################################
############  Results using threshold 0.9  ###################
##############################################################
###################  Nearest Neighbors  ##################
Trained in : 0.015625
[[ 18  21]
 [ 11 102]]
              precision    recall  f1-score   support

           0       0.62      0.46      0.53        39
           1       0.83      0.90      0.86       113

    accuracy                           0.79       152
   macro avg       0.72      0.68      0.70       152
weighted avg       0.78      0.79      0.78       152

###################  Gradient Boosting Classifier  ##################
Trained in : 11.734375
[[ 22  17]
 [  5 108]]
              precision    recall  f1-score   support

           0       0.81      0.56      0.67        39
           1       0.86      0.96      0.91       113

    accuracy                           0.86       152
   macro avg       0.84      0.76      0.79       152
weighted avg       0.85      0.86      0.85       152

###################  Decision Tree  ##################
Trained in : 0.578125
[[26 13]
 [27 86]]
              precision    recall  f1-score   support

           0       0.49      0.67      0.57        39
           1       0.87      0.76      0.81       113

    accuracy                           0.74       152
   macro avg       0.68      0.71      0.69       152
weighted avg       0.77      0.74      0.75       152

###################  Random Forest  ##################
Trained in : 12.4375
[[ 21  18]
 [  4 109]]
              precision    recall  f1-score   support

           0       0.84      0.54      0.66        39
           1       0.86      0.96      0.91       113

    accuracy                           0.86       152
   macro avg       0.85      0.75      0.78       152
weighted avg       0.85      0.86      0.84       152

###################  Naive Bayes  ##################
Trained in : 0.015625
[[30  9]
 [59 54]]
              precision    recall  f1-score   support

           0       0.34      0.77      0.47        39
           1       0.86      0.48      0.61       113

    accuracy                           0.55       152
   macro avg       0.60      0.62      0.54       152
weighted avg       0.72      0.55      0.58       152

###################  Ada Boost  ##################
Trained in : 2.640625
[[ 26  13]
 [ 10 103]]
              precision    recall  f1-score   support

           0       0.72      0.67      0.69        39
           1       0.89      0.91      0.90       113

    accuracy                           0.85       152
   macro avg       0.81      0.79      0.80       152
weighted avg       0.85      0.85      0.85       152

##############################################################
############  Results using threshold 0.7  ###################
##############################################################
###################  Nearest Neighbors  ##################
Trained in : 0.015625
[[ 7 32]
 [19 94]]
              precision    recall  f1-score   support

           0       0.27      0.18      0.22        39
           1       0.75      0.83      0.79       113

    accuracy                           0.66       152
   macro avg       0.51      0.51      0.50       152
weighted avg       0.62      0.66      0.64       152

###################  Gradient Boosting Classifier  ##################
Trained in : 8.6875
[[ 24  15]
 [  7 106]]
              precision    recall  f1-score   support

           0       0.77      0.62      0.69        39
           1       0.88      0.94      0.91       113

    accuracy                           0.86       152
   macro avg       0.83      0.78      0.80       152
weighted avg       0.85      0.86      0.85       152

###################  Decision Tree  ##################
Trained in : 0.234375
[[26 13]
 [24 89]]
              precision    recall  f1-score   support

           0       0.52      0.67      0.58        39
           1       0.87      0.79      0.83       113

    accuracy                           0.76       152
   macro avg       0.70      0.73      0.71       152
weighted avg       0.78      0.76      0.77       152

###################  Random Forest  ##################
Trained in : 10.890625
[[ 20  19]
 [  4 109]]
              precision    recall  f1-score   support

           0       0.83      0.51      0.63        39
           1       0.85      0.96      0.90       113

    accuracy                           0.85       152
   macro avg       0.84      0.74      0.77       152
weighted avg       0.85      0.85      0.84       152

###################  Naive Bayes  ##################
Trained in : 0.015625
[[30  9]
 [62 51]]
              precision    recall  f1-score   support

           0       0.33      0.77      0.46        39
           1       0.85      0.45      0.59       113

    accuracy                           0.53       152
   macro avg       0.59      0.61      0.52       152
weighted avg       0.72      0.53      0.56       152

###################  Ada Boost  ##################
Trained in : 1.984375
[[ 26  13]
 [  8 105]]
              precision    recall  f1-score   support

           0       0.76      0.67      0.71        39
           1       0.89      0.93      0.91       113

    accuracy                           0.86       152
   macro avg       0.83      0.80      0.81       152
weighted avg       0.86      0.86      0.86       152

##############################################################
############  Results using threshold 0.5  ###################
##############################################################
###################  Nearest Neighbors  ##################
Trained in : 0.015625
[[ 11  28]
 [  8 105]]
              precision    recall  f1-score   support

           0       0.58      0.28      0.38        39
           1       0.79      0.93      0.85       113

    accuracy                           0.76       152
   macro avg       0.68      0.61      0.62       152
weighted avg       0.74      0.76      0.73       152

###################  Gradient Boosting Classifier  ##################
Trained in : 6.953125
[[ 23  16]
 [  5 108]]
              precision    recall  f1-score   support

           0       0.82      0.59      0.69        39
           1       0.87      0.96      0.91       113

    accuracy                           0.86       152
   macro avg       0.85      0.77      0.80       152
weighted avg       0.86      0.86      0.85       152

###################  Decision Tree  ##################
Trained in : 0.203125
[[27 12]
 [20 93]]
              precision    recall  f1-score   support

           0       0.57      0.69      0.63        39
           1       0.89      0.82      0.85       113

    accuracy                           0.79       152
   macro avg       0.73      0.76      0.74       152
weighted avg       0.81      0.79      0.80       152

###################  Random Forest  ##################
Trained in : 9.8125
[[ 20  19]
 [  3 110]]
              precision    recall  f1-score   support

           0       0.87      0.51      0.65        39
           1       0.85      0.97      0.91       113

    accuracy                           0.86       152
   macro avg       0.86      0.74      0.78       152
weighted avg       0.86      0.86      0.84       152

###################  Naive Bayes  ##################
Trained in : 0.0
[[29 10]
 [49 64]]
              precision    recall  f1-score   support

           0       0.37      0.74      0.50        39
           1       0.86      0.57      0.68       113

    accuracy                           0.61       152
   macro avg       0.62      0.65      0.59       152
weighted avg       0.74      0.61      0.64       152

###################  Ada Boost  ##################
Trained in : 1.59375
[[ 22  17]
 [  7 106]]
              precision    recall  f1-score   support

           0       0.76      0.56      0.65        39
           1       0.86      0.94      0.90       113

    accuracy                           0.84       152
   macro avg       0.81      0.75      0.77       152
weighted avg       0.84      0.84      0.83       152

##############################################################
############  Results using threshold 0.3  ###################
##############################################################
###################  Nearest Neighbors  ##################
Trained in : 0.015625
[[ 11  28]
 [ 11 102]]
              precision    recall  f1-score   support

           0       0.50      0.28      0.36        39
           1       0.78      0.90      0.84       113

    accuracy                           0.74       152
   macro avg       0.64      0.59      0.60       152
weighted avg       0.71      0.74      0.72       152

###################  Gradient Boosting Classifier  ##################
Trained in : 5.453125
[[ 25  14]
 [  4 109]]
              precision    recall  f1-score   support

           0       0.86      0.64      0.74        39
           1       0.89      0.96      0.92       113

    accuracy                           0.88       152
   macro avg       0.87      0.80      0.83       152
weighted avg       0.88      0.88      0.88       152

###################  Decision Tree  ##################
Trained in : 0.265625
[[25 14]
 [15 98]]
              precision    recall  f1-score   support

           0       0.62      0.64      0.63        39
           1       0.88      0.87      0.87       113

    accuracy                           0.81       152
   macro avg       0.75      0.75      0.75       152
weighted avg       0.81      0.81      0.81       152

###################  Random Forest  ##################
Trained in : 9.125
[[ 19  20]
 [  2 111]]
              precision    recall  f1-score   support

           0       0.90      0.49      0.63        39
           1       0.85      0.98      0.91       113

    accuracy                           0.86       152
   macro avg       0.88      0.73      0.77       152
weighted avg       0.86      0.86      0.84       152

###################  Naive Bayes  ##################
Trained in : 0.015625
[[24 15]
 [39 74]]
              precision    recall  f1-score   support

           0       0.38      0.62      0.47        39
           1       0.83      0.65      0.73       113

    accuracy                           0.64       152
   macro avg       0.61      0.64      0.60       152
weighted avg       0.72      0.64      0.67       152

###################  Ada Boost  ##################
Trained in : 1.3125
[[ 23  16]
 [ 11 102]]
              precision    recall  f1-score   support

           0       0.68      0.59      0.63        39
           1       0.86      0.90      0.88       113

    accuracy                           0.82       152
   macro avg       0.77      0.75      0.76       152
weighted avg       0.82      0.82      0.82       152

##############################################################
############  Results using threshold 0.2  ###################
##############################################################
###################  Nearest Neighbors  ##################
Trained in : 0.015625
[[12 27]
 [17 96]]
              precision    recall  f1-score   support

           0       0.41      0.31      0.35        39
           1       0.78      0.85      0.81       113

    accuracy                           0.71       152
   macro avg       0.60      0.58      0.58       152
weighted avg       0.69      0.71      0.70       152

###################  Gradient Boosting Classifier  ##################
Trained in : 4.921875
[[ 20  19]
 [  8 105]]
              precision    recall  f1-score   support

           0       0.71      0.51      0.60        39
           1       0.85      0.93      0.89       113

    accuracy                           0.82       152
   macro avg       0.78      0.72      0.74       152
weighted avg       0.81      0.82      0.81       152

###################  Decision Tree  ##################
Trained in : 0.125
[[24 15]
 [17 96]]
              precision    recall  f1-score   support

           0       0.59      0.62      0.60        39
           1       0.86      0.85      0.86       113

    accuracy                           0.79       152
   macro avg       0.73      0.73      0.73       152
weighted avg       0.79      0.79      0.79       152

###################  Random Forest  ##################
Trained in : 8.71875
[[ 18  21]
 [  3 110]]
              precision    recall  f1-score   support

           0       0.86      0.46      0.60        39
           1       0.84      0.97      0.90       113

    accuracy                           0.84       152
   macro avg       0.85      0.72      0.75       152
weighted avg       0.84      0.84      0.82       152

###################  Naive Bayes  ##################
Trained in : 0.015625
[[29 10]
 [45 68]]
              precision    recall  f1-score   support

           0       0.39      0.74      0.51        39
           1       0.87      0.60      0.71       113

    accuracy                           0.64       152
   macro avg       0.63      0.67      0.61       152
weighted avg       0.75      0.64      0.66       152

###################  Ada Boost  ##################
Trained in : 1.1875
[[ 22  17]
 [ 13 100]]
              precision    recall  f1-score   support

           0       0.63      0.56      0.59        39
           1       0.85      0.88      0.87       113

    accuracy                           0.80       152
   macro avg       0.74      0.72      0.73       152
weighted avg       0.80      0.80      0.80       152

##############################################################
############  Results using threshold 0.1  ###################
##############################################################
###################  Nearest Neighbors  ##################
Trained in : 0.0
[[ 6 33]
 [16 97]]
              precision    recall  f1-score   support

           0       0.27      0.15      0.20        39
           1       0.75      0.86      0.80       113

    accuracy                           0.68       152
   macro avg       0.51      0.51      0.50       152
weighted avg       0.62      0.68      0.64       152

###################  Gradient Boosting Classifier  ##################
Trained in : 4.234375
[[ 19  20]
 [  5 108]]
              precision    recall  f1-score   support

           0       0.79      0.49      0.60        39
           1       0.84      0.96      0.90       113

    accuracy                           0.84       152
   macro avg       0.82      0.72      0.75       152
weighted avg       0.83      0.84      0.82       152

###################  Decision Tree  ##################
Trained in : 0.15625
[[22 17]
 [20 93]]
              precision    recall  f1-score   support

           0       0.52      0.56      0.54        39
           1       0.85      0.82      0.83       113

    accuracy                           0.76       152
   macro avg       0.68      0.69      0.69       152
weighted avg       0.76      0.76      0.76       152

###################  Random Forest  ##################
Trained in : 8.40625
[[ 17  22]
 [  5 108]]
              precision    recall  f1-score   support

           0       0.77      0.44      0.56        39
           1       0.83      0.96      0.89       113

    accuracy                           0.82       152
   macro avg       0.80      0.70      0.72       152
weighted avg       0.82      0.82      0.80       152

###################  Naive Bayes  ##################
Trained in : 0.015625
[[ 11  28]
 [  6 107]]
              precision    recall  f1-score   support

           0       0.65      0.28      0.39        39
           1       0.79      0.95      0.86       113

    accuracy                           0.78       152
   macro avg       0.72      0.61      0.63       152
weighted avg       0.76      0.78      0.74       152

###################  Ada Boost  ##################
Trained in : 1.046875
[[21 18]
 [17 96]]
              precision    recall  f1-score   support

           0       0.55      0.54      0.55        39
           1       0.84      0.85      0.85       113

    accuracy                           0.77       152
   macro avg       0.70      0.69      0.70       152
weighted avg       0.77      0.77      0.77       152

##############################################################
############  Results using threshold 0.05  ###################
##############################################################
###################  Nearest Neighbors  ##################
Trained in : 0.0
[[10 29]
 [16 97]]
              precision    recall  f1-score   support

           0       0.38      0.26      0.31        39
           1       0.77      0.86      0.81       113

    accuracy                           0.70       152
   macro avg       0.58      0.56      0.56       152
weighted avg       0.67      0.70      0.68       152

###################  Gradient Boosting Classifier  ##################
Trained in : 3.8125
[[ 18  21]
 [  3 110]]
              precision    recall  f1-score   support

           0       0.86      0.46      0.60        39
           1       0.84      0.97      0.90       113

    accuracy                           0.84       152
   macro avg       0.85      0.72      0.75       152
weighted avg       0.84      0.84      0.82       152

###################  Decision Tree  ##################
Trained in : 0.09375
[[19 20]
 [18 95]]
              precision    recall  f1-score   support

           0       0.51      0.49      0.50        39
           1       0.83      0.84      0.83       113

    accuracy                           0.75       152
   macro avg       0.67      0.66      0.67       152
weighted avg       0.75      0.75      0.75       152

###################  Random Forest  ##################
Trained in : 8.03125
[[ 14  25]
 [  3 110]]
              precision    recall  f1-score   support

           0       0.82      0.36      0.50        39
           1       0.81      0.97      0.89       113

    accuracy                           0.82       152
   macro avg       0.82      0.67      0.69       152
weighted avg       0.82      0.82      0.79       152

###################  Naive Bayes  ##################
Trained in : 0.015625
[[36  3]
 [76 37]]
              precision    recall  f1-score   support

           0       0.32      0.92      0.48        39
           1       0.93      0.33      0.48       113

    accuracy                           0.48       152
   macro avg       0.62      0.63      0.48       152
weighted avg       0.77      0.48      0.48       152

###################  Ada Boost  ##################
Trained in : 0.953125
[[ 19  20]
 [ 10 103]]
              precision    recall  f1-score   support

           0       0.66      0.49      0.56        39
           1       0.84      0.91      0.87       113

    accuracy                           0.80       152
   macro avg       0.75      0.70      0.72       152
weighted avg       0.79      0.80      0.79       152

##############################################################
############  Results using threshold 0.01  ###################
##############################################################
###################  Nearest Neighbors  ##################
Trained in : 0.0
[[ 19  20]
 [ 12 101]]
              precision    recall  f1-score   support

           0       0.61      0.49      0.54        39
           1       0.83      0.89      0.86       113

    accuracy                           0.79       152
   macro avg       0.72      0.69      0.70       152
weighted avg       0.78      0.79      0.78       152

###################  Gradient Boosting Classifier  ##################
Trained in : 2.3125
[[ 19  20]
 [  8 105]]
              precision    recall  f1-score   support

           0       0.70      0.49      0.58        39
           1       0.84      0.93      0.88       113

    accuracy                           0.82       152
   macro avg       0.77      0.71      0.73       152
weighted avg       0.81      0.82      0.80       152

###################  Decision Tree  ##################
Trained in : 0.078125
[[22 17]
 [24 89]]
              precision    recall  f1-score   support

           0       0.48      0.56      0.52        39
           1       0.84      0.79      0.81       113

    accuracy                           0.73       152
   macro avg       0.66      0.68      0.67       152
weighted avg       0.75      0.73      0.74       152

###################  Random Forest  ##################
Trained in : 6.453125
[[ 19  20]
 [  4 109]]
              precision    recall  f1-score   support

           0       0.83      0.49      0.61        39
           1       0.84      0.96      0.90       113

    accuracy                           0.84       152
   macro avg       0.84      0.73      0.76       152
weighted avg       0.84      0.84      0.83       152

###################  Naive Bayes  ##################
Trained in : 0.0
[[20 19]
 [20 93]]
              precision    recall  f1-score   support

           0       0.50      0.51      0.51        39
           1       0.83      0.82      0.83       113

    accuracy                           0.74       152
   macro avg       0.67      0.67      0.67       152
weighted avg       0.75      0.74      0.74       152

###################  Ada Boost  ##################
Trained in : 0.65625
[[16 23]
 [19 94]]
              precision    recall  f1-score   support

           0       0.46      0.41      0.43        39
           1       0.80      0.83      0.82       113

    accuracy                           0.72       152
   macro avg       0.63      0.62      0.62       152
weighted avg       0.71      0.72      0.72       152


Process finished with exit code 0